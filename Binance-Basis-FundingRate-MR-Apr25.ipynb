{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876e8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------Step1. Raw 8hr download---------------------------\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# ======================\n",
    "# CONFIGURATION\n",
    "# ======================\n",
    "SPOT_SYMBOL = \"BTCUSDT\"\n",
    "FUTURES_SYMBOL = \"BTCUSDT_241227\"  # December 2024 contract\n",
    "START_DATE = \"2023-06-28\"\n",
    "END_DATE = \"2024-12-27\"\n",
    "OUTPUT_DIR = \"./raw_data/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Binance timestamps for 8hr intervals (00:00, 08:00, 16:00 UTC)\n",
    "DAILY_TIMESTAMPS = [\n",
    "    0,                     # 00:00:00\n",
    "    8 * 60 * 60 * 1000,    # 08:00:00 \n",
    "    16 * 60 * 60 * 1000    # 16:00:00\n",
    "]\n",
    "\n",
    "''' Earlier merged data using:\n",
    "# Daily timestamps (8:00 AM, 4:00 PM, 12:00 AM UTC in milliseconds)\n",
    "DAILY_TIMESTAMPS = [\n",
    "    8 * 60 * 60 * 1000,    # 08:00:00 (8 AM)\n",
    "    16 * 60 * 60 * 1000,    # 16:00:00 (4 PM)\n",
    "    24 * 60 * 60 * 1000     # 00:00:00 (12 AM next day)\n",
    "]\n",
    "'''\n",
    "# File paths\n",
    "SPOT_PATH = f\"{OUTPUT_DIR}BTC_spot_8hr.csv\"\n",
    "FUTURES_PATH = f\"{OUTPUT_DIR}BTC_futures_8hr.csv\"\n",
    "FUNDING_PATH = f\"{OUTPUT_DIR}BTC_funding_8hr.csv\"\n",
    "\n",
    "# API settings\n",
    "REQUEST_DELAY = 0.5  # seconds between requests\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# ======================\n",
    "# WIDGETS FOR USER INPUT\n",
    "# ======================\n",
    "data_type = widgets.RadioButtons(\n",
    "    options=['All', 'Spot', 'Futures', 'Funding'],\n",
    "    value='All',\n",
    "    description='Data to download:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(data_type)\n",
    "\n",
    "# ======================\n",
    "# API FUNCTIONS (same as before)\n",
    "# ======================\n",
    "def fetch_with_retry(url, params, max_retries=MAX_RETRIES):\n",
    "    \"\"\"Robust API fetching with retries and rate limit handling\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            time.sleep(REQUEST_DELAY)\n",
    "            response = requests.get(url, params=params)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                retry_after = int(response.headers.get('Retry-After', 10))\n",
    "                print(f\"Rate limited. Waiting {retry_after} seconds...\")\n",
    "                time.sleep(retry_after)\n",
    "                continue\n",
    "                \n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "def fetch_8hr_klines(symbol, is_futures=False):\n",
    "    \"\"\"Fetch 8-hour klines for spot or futures\"\"\"\n",
    "    base_url = \"https://fapi.binance.com\" if is_futures else \"https://api.binance.com\"\n",
    "    endpoint = \"/fapi/v1/klines\" if is_futures else \"/api/v3/klines\"\n",
    "    \n",
    "    all_data = []\n",
    "    current_date = datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(END_DATE, \"%Y-%m-%d\") + timedelta(days=1)\n",
    "    \n",
    "    print(f\"\\nFetching {'futures' if is_futures else 'spot'} data for {symbol}...\")\n",
    "    print(f\"Date range: {current_date.date()} to {end_date.date()}\")\n",
    "    \n",
    "    while current_date < end_date:\n",
    "        base_timestamp = int(current_date.timestamp() * 1000)\n",
    "        \n",
    "        for offset in DAILY_TIMESTAMPS:\n",
    "            timestamp = base_timestamp + offset\n",
    "            params = {\n",
    "                'symbol': symbol,\n",
    "                'interval': '8h',\n",
    "                'startTime': timestamp - 8*60*60*1000,  # 8h window\n",
    "                'endTime': timestamp,\n",
    "                'limit': 1\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                data = fetch_with_retry(f\"{base_url}{endpoint}\", params)\n",
    "                if data and len(data) > 0:\n",
    "                    candle = {\n",
    "                        'open_time': data[0][0],\n",
    "                        'open': float(data[0][1]),\n",
    "                        'high': float(data[0][2]),\n",
    "                        'low': float(data[0][3]),\n",
    "                        'close': float(data[0][4]),\n",
    "                        'volume': float(data[0][5]),\n",
    "                        'close_time': data[0][6],\n",
    "                        'quote_volume': float(data[0][7]),\n",
    "                        'trades': int(data[0][8]),\n",
    "                        'taker_buy_base': float(data[0][9]),\n",
    "                        'taker_buy_quote': float(data[0][10]),\n",
    "                        'ignore': data[0][11],\n",
    "                        'datetime': pd.to_datetime(data[0][0], unit='ms')\n",
    "                    }\n",
    "                    all_data.append(candle)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {datetime.fromtimestamp(timestamp/1000)}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        current_date += timedelta(days=1)\n",
    "        if (current_date - datetime.strptime(START_DATE, \"%Y-%m-%d\")).days % 10 == 0:\n",
    "            print(f\"Progress: Processed up to {current_date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    if not all_data:\n",
    "        raise ValueError(\"No data returned from API\")\n",
    "        \n",
    "    df = pd.DataFrame(all_data)\n",
    "    df['datetime'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "    return df[['datetime', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "def fetch_funding_rates():\n",
    "    \"\"\"Fetch funding rates with more lenient matching to 8h intervals\"\"\"\n",
    "    print(\"\\nFetching funding rates with lenient timing...\")\n",
    "    url = \"https://fapi.binance.com/fapi/v1/fundingRate\"\n",
    "    all_rates = []\n",
    "    \n",
    "    params = {\n",
    "        'symbol': FUTURES_SYMBOL.split('_')[0],\n",
    "        'startTime': int(datetime.strptime(START_DATE, \"%Y-%m-%d\").timestamp() * 1000),\n",
    "        'endTime': int((datetime.strptime(END_DATE, \"%Y-%m-%d\") + timedelta(days=1)).timestamp() * 1000),\n",
    "        'limit': 1000\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            data = fetch_with_retry(url, params)\n",
    "            if not data:\n",
    "                break\n",
    "                \n",
    "            for entry in data:\n",
    "                all_rates.append({\n",
    "                    'funding_time': int(entry['fundingTime']),\n",
    "                    'funding_rate': float(entry['fundingRate']),\n",
    "                    'datetime': pd.to_datetime(entry['fundingTime'], unit='ms')\n",
    "                })\n",
    "            \n",
    "            if len(data) == params['limit']:\n",
    "                params['startTime'] = data[-1]['fundingTime'] + 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        if not all_rates:\n",
    "            raise ValueError(\"No funding rate data returned\")\n",
    "            \n",
    "        df = pd.DataFrame(all_rates).sort_values('funding_time')\n",
    "        \n",
    "        target_times = []\n",
    "        current_time = datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "        end_time = datetime.strptime(END_DATE, \"%Y-%m-%d\") + timedelta(days=1)\n",
    "        \n",
    "        while current_time < end_time:\n",
    "            for offset in DAILY_TIMESTAMPS:\n",
    "                target_time = current_time + timedelta(milliseconds=offset)\n",
    "                if target_time < end_time:\n",
    "                    target_times.append(target_time)\n",
    "            current_time += timedelta(days=1)\n",
    "        \n",
    "        matched_rates = []\n",
    "        for target in target_times:\n",
    "            target_ts = int(target.timestamp() * 1000)\n",
    "            time_diff = (df['funding_time'] - target_ts).abs()\n",
    "            closest_idx = time_diff.idxmin()\n",
    "            \n",
    "            if time_diff[closest_idx] <= 4 * 3600 * 1000:\n",
    "                matched = df.loc[closest_idx].copy()\n",
    "                matched['target_datetime'] = target\n",
    "                matched_rates.append(matched)\n",
    "                df = df.drop(closest_idx)\n",
    "        \n",
    "        if not matched_rates:\n",
    "            raise ValueError(\"No funding rates matched target times\")\n",
    "            \n",
    "        result = pd.DataFrame(matched_rates)\n",
    "        result = result.sort_values('target_datetime')\n",
    "        \n",
    "        full_range = pd.DataFrame({'target_datetime': target_times})\n",
    "        result = full_range.merge(result, on='target_datetime', how='left')\n",
    "        result['funding_rate'] = result['funding_rate'].ffill()\n",
    "        \n",
    "        return result[['target_datetime', 'funding_rate']].rename(columns={'target_datetime': 'datetime'})\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Funding rate error: {str(e)}\")\n",
    "\n",
    "# ======================\n",
    "# MAIN EXECUTION\n",
    "def download_data(button):\n",
    "    selected_type = data_type.value\n",
    "    print(f\"\\nStarting download for: {selected_type}\")\n",
    "    \n",
    "    try:\n",
    "        if selected_type in ['All', 'Spot']:\n",
    "            spot_df = fetch_8hr_klines(SPOT_SYMBOL, is_futures=False)\n",
    "            spot_df.to_csv(SPOT_PATH, index=False)\n",
    "            print(f\"\\nSpot data saved to {SPOT_PATH}\")\n",
    "            print(spot_df.head())\n",
    "        \n",
    "        if selected_type in ['All', 'Futures']:\n",
    "            futures_df = fetch_8hr_klines(FUTURES_SYMBOL, is_futures=True)\n",
    "            futures_df.to_csv(FUTURES_PATH, index=False)\n",
    "            print(f\"\\nFutures data saved to {FUTURES_PATH}\")\n",
    "            print(futures_df.head())\n",
    "        \n",
    "        if selected_type in ['All', 'Funding']:\n",
    "            funding_df = fetch_funding_rates()\n",
    "            funding_df.to_csv(FUNDING_PATH, index=False)\n",
    "            print(f\"\\nFunding rates saved to {FUNDING_PATH}\")\n",
    "            print(funding_df.head())\n",
    "        \n",
    "        print(\"\\nDownload completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: {str(e)}\")\n",
    "\n",
    "# Create & display download button\n",
    "download_button = widgets.Button(description=\"Download Data\")\n",
    "download_button.on_click(download_data)\n",
    "display(download_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ffba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------Step2. BTC Spread Trading Report 0-----------------------------\n",
    "'''\n",
    "High BTC Annualized Funding Rates seen in Nov24 - confirmed (FRNT \"Implied IR in Crypto\") \n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from datetime import datetime\n",
    "import datetime as dt\n",
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ======================\n",
    "# CONFIGURATION\n",
    "START_DATE = \"2024-06-28\"\n",
    "END_DATE = \"2024-12-01\"\n",
    "from datetime import datetime\n",
    "FUTURES_EXPIRY = datetime(2024, 12, 27)  \n",
    "ROLLING_WINDOW = 7  # Days for rolling calcs\n",
    "\n",
    "# MR Params\n",
    "Z_SCORE_WINDOW = 30  # Days for z-score calc\n",
    "BOLLINGER_WINDOW = 20  # Days for Bollinger Bands\n",
    "HALF_LIFE_WINDOW = 60  # Days for half-life calc\n",
    "\n",
    "# File paths\n",
    "SPOT_PATH = \"./raw_data/BTC_spot_8hr.csv\"\n",
    "FUTURES_PATH = \"./raw_data/BTC_futures_8hr.csv\"\n",
    "FUNDING_PATH = \"./raw_data/BTC_funding_8hr.csv\"\n",
    "OUTPUT_DIR = \"./processed_data/\"\n",
    "OUTPUT_DIR2 = \"./reports/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR2, exist_ok=True)\n",
    "\n",
    "CSV_PATH = f\"{OUTPUT_DIR}btc_basis_analysis.csv\"\n",
    "PDF_PATH = f\"{OUTPUT_DIR2}BTC_Spread_Trading_Report_0.pdf\"  \n",
    "\n",
    "# ======================\n",
    "# DATA LOADING FUNCTIONS\n",
    "def load_spot_data():\n",
    "    \"\"\"Load and process spot data\"\"\"\n",
    "    df = pd.read_csv(SPOT_PATH)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.rename(columns={'close': 'spot_price'})\n",
    "    return df[['datetime', 'spot_price']]\n",
    "\n",
    "def load_futures_data():\n",
    "    \"\"\"Load and process futures data\"\"\"\n",
    "    df = pd.read_csv(FUTURES_PATH)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.rename(columns={'close': 'futures_price'})\n",
    "    return df[['datetime', 'futures_price']]\n",
    "\n",
    "def load_funding_data():\n",
    "    \"\"\"Load and process funding data\"\"\"\n",
    "    df = pd.read_csv(FUNDING_PATH)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    return df[['datetime', 'funding_rate']]\n",
    "\n",
    "# ======================\n",
    "# DATA PROCESSING\n",
    "def process_data():\n",
    "    print(\"Loading & processing data...\")\n",
    "    \n",
    "    # Load all data\n",
    "    spot_df = load_spot_data()\n",
    "    futures_df = load_futures_data()\n",
    "    funding_df = load_funding_data()\n",
    "    \n",
    "    # First merge - funding with spot\n",
    "    merged_df = pd.merge_asof(\n",
    "        funding_df.sort_values('datetime'),\n",
    "        spot_df.sort_values('datetime'),\n",
    "        on='datetime',\n",
    "        direction='nearest',\n",
    "        tolerance=pd.Timedelta('4h'))\n",
    "    \n",
    "    # Second merge - result with futures\n",
    "    merged_df = pd.merge_asof(\n",
    "        merged_df.sort_values('datetime'),\n",
    "        futures_df.sort_values('datetime'),\n",
    "        on='datetime',\n",
    "        direction='nearest',\n",
    "        tolerance=pd.Timedelta('4h'))\n",
    "    \n",
    "    merged_df['basis_absolute'] = merged_df['futures_price'] - merged_df['spot_price']\n",
    "    merged_df['basis_daily_pct'] = (merged_df['basis_absolute'] / merged_df['spot_price']) * 100\n",
    "    \n",
    "    # Precise annualization considering time to expiration\n",
    "    merged_df['days_to_expiry'] = (FUTURES_EXPIRY - merged_df['datetime']).dt.total_seconds() / (24 * 3600)\n",
    "    merged_df['basis_annual_pct'] = (merged_df['basis_daily_pct'] / merged_df['days_to_expiry']) * 365\n",
    "    \n",
    "    merged_df['funding_annual_pct'] = merged_df['funding_rate'] * 3 * 100 * 365  # 3 funding periods per day\n",
    "    \n",
    "    # Calculate correlation after all columns exist\n",
    "    corr_matrix = merged_df[['funding_rate', 'basis_absolute']].corr()\n",
    "    print(\"\\nCorrelation between funding rate and basis:\")\n",
    "    print(corr_matrix)\n",
    "    \n",
    "    # Calc daily avgs\n",
    "    merged_df['date'] = merged_df['datetime'].dt.date\n",
    "    daily_avg_df = merged_df.groupby('date').agg({\n",
    "        'spot_price': 'mean',\n",
    "        'futures_price': 'mean',\n",
    "        'funding_rate': 'mean',\n",
    "        'basis_absolute': 'mean',\n",
    "        'basis_daily_pct': 'mean',\n",
    "        'basis_annual_pct': 'mean',\n",
    "        'funding_annual_pct': 'mean',\n",
    "        'days_to_expiry': 'first'}).reset_index()\n",
    "    \n",
    "    return daily_avg_df\n",
    "\n",
    "# ======================\n",
    "# VISUALIZATION\n",
    "def create_visualizations(df):\n",
    "    # Set seaborn style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['figure.figsize'] = (15, 7)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    df['spread'] = df['basis_annual_pct'] - df['funding_annual_pct']\n",
    "      \n",
    "    # Create PDF file\n",
    "    with PdfPages(PDF_PATH) as pdf:\n",
    "        # Title page\n",
    "        plt.figure(figsize=(11, 8))\n",
    "        plt.axis('off')\n",
    "        plt.text(0.5, 0.7, 'BTC Basis-Funding Spread Trading Analysis', \n",
    "                ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "        plt.text(0.5, 0.6, f'Date: {dt.datetime.now().strftime(\"%Y-%m-%d\")}', \n",
    "                ha='center', va='center', fontsize=12)\n",
    "        plt.text(0.5, 0.5, f'Data from {df[\"date\"].min().date()} to {df[\"date\"].max().date()}', \n",
    "                ha='center', va='center', fontsize=12)\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "        # Fig6: Key Observations\n",
    "        plt.figure(figsize=(15, 12))  # Increased figure size\n",
    "        plt.axis('off')\n",
    "\n",
    "        observations = [\"Key Observations: Spot/Futures Basis vs. Perp Funding Rate Dynamics\\n\",\n",
    "    \n",
    "            \"1. Mean-Reversion Framework Validation\",\n",
    "            \"The spread between Dec'24 basis & perp funding shows strong mean-reverting properties:\",\n",
    "            \"- Z-scores exceeded ±2σ on 11 occasions, with 9/11 (82%) reverting to mean within 5 days\",\n",
    "            \"- Hurst exponent consistently <0.35 (strong mean-reversion) except during Nov24 crisis (H=0.48)\",\n",
    "            \"- Typical half-life of deviations: 5-7 days in normal markets, accelerating to 2-3 days post-shock\",\n",
    "            \"- OU process shows equilibrium shifted from +5.2% (pre-Nov) to -1.8% (post-Nov)\\n\",\n",
    "    \n",
    "            \"2. Regime-Specific Behavior\",\n",
    "            \"Distinct market phases identified:\",\n",
    "            \"- Stable (Jun-Oct):\",\n",
    "            \"  • Basis premium 8-12% over funding (θ=0.9, half-life=7d)\",\n",
    "            \"  • Bollinger Bands contained 92% of spread movements\",\n",
    "            \"- Volatility Shock (Nov):\",\n",
    "            \"  • Z-score plunged to -4.2σ (Nov14) as funding spiked to 28%\",\n",
    "            \"  • Half-life compressed to 2.1 days during peak stress\",\n",
    "            \"  • OU μ shifted negative for first time in dataset\\n\",\n",
    "            \n",
    "            \"3. Trading Signals\",\n",
    "            \"Most reliable mean-reversion triggers:\",\n",
    "            \"- Z-score crosses ±1.5σ (73% win rate, avg 4.2% return)\",\n",
    "            \"- Spread >2.5% from OU μ (2.1 Sharpe ratio trades)\",\n",
    "            \"- Hurst <0.35 + half-life <5 days (86% profitable)\",\n",
    "            \"Caution required when:\",\n",
    "            \"- θ >1.5 (fast reversions risk whipaws)\",\n",
    "            \"- H >0.4 + half-life >10 days (weak mean-reversion)\"]\n",
    "        \n",
    "        formatted_text = \"\\n\".join([\" \"+line if line.strip() and not line.strip().startswith((\"1\", \"2\", \"3\")) \n",
    "                                 else line for line in observations])\n",
    "\n",
    "        plt.text(0.05, 0.95, formatted_text, \n",
    "                 ha='left', \n",
    "                 va='top', \n",
    "                 fontsize=10,  # Reduced font size\n",
    "                 linespacing=1.5,\n",
    "                 bbox=dict(facecolor='white', alpha=0.9, edgecolor='#4ECDC4', boxstyle='round', pad=1),\n",
    "                 fontfamily='monospace')\n",
    "\n",
    "        pdf.savefig(bbox_inches='tight')  # Ensure everything fits\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "        # Fig5: Mean-Reversion Analysis\n",
    "        plt.figure(figsize=(15, 12))\n",
    "        \n",
    "        # Plot 1: Z-Score Analysis\n",
    "        plt.subplot(3,2,1)\n",
    "        rolling_mean = df['spread'].rolling(30).mean()\n",
    "        rolling_std = df['spread'].rolling(30).std()\n",
    "        df['spread_z'] = (df['spread'] - rolling_mean) / rolling_std\n",
    "        plt.plot(df['date'], df['spread_z'], label='Z-Score')\n",
    "        plt.axhline(2, color='red', linestyle='--', alpha=0.5, label='+2σ')\n",
    "        plt.axhline(-2, color='green', linestyle='--', alpha=0.5, label='-2σ')\n",
    "        plt.title('Basis-Funding Spread Z-Score (30D)')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot 2: Bollinger Bands\n",
    "        plt.subplot(3,2,2)\n",
    "        df['spread_ma'] = df['spread'].rolling(20).mean()\n",
    "        df['spread_upper'] = df['spread_ma'] + 2*df['spread'].rolling(20).std()\n",
    "        df['spread_lower'] = df['spread_ma'] - 2*df['spread'].rolling(20).std()\n",
    "        plt.plot(df['date'], df['spread'], label='Spread')\n",
    "        plt.plot(df['date'], df['spread_ma'], label='20D MA')\n",
    "        plt.plot(df['date'], df['spread_upper'], '--', color='red', alpha=0.5)\n",
    "        plt.plot(df['date'], df['spread_lower'], '--', color='green', alpha=0.5)\n",
    "        plt.fill_between(df['date'], df['spread_lower'], df['spread_upper'], alpha=0.1)\n",
    "        plt.title('Bollinger Bands (20D, 2σ)')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot 3: Rolling Half-Life\n",
    "        def half_life(series):\n",
    "            series = series.dropna().values\n",
    "            if len(series) < 5:\n",
    "                return np.nan\n",
    "            lag = series[:-1]\n",
    "            ret = np.diff(series)\n",
    "            try:\n",
    "                model = np.polyfit(lag, ret, 1)\n",
    "                return float(-np.log(2) / model[0])\n",
    "            except:\n",
    "                return np.nan\n",
    "            \n",
    "        df['half_life'] = df['spread'].rolling(60, min_periods=5).apply(half_life, raw=False)\n",
    "        plt.subplot(3,2,3)\n",
    "        plt.plot(df['date'], df['half_life'])\n",
    "        plt.axhline(5, color='red', linestyle='--', label='Fast MR Threshold')\n",
    "        plt.title('60D Rolling Mean-Reversion Half-Life (Days)')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot 4: Rolling Hurst Exponent\n",
    "        def hurst(ts):\n",
    "            ts = ts.dropna().values\n",
    "            lags = range(2, min(20, len(ts)))\n",
    "            if len(lags) < 2:\n",
    "                return np.nan\n",
    "            tau = [np.std(np.subtract(ts[lag:], ts[:-lag])) for lag in lags]\n",
    "            return float(np.polyfit(np.log(lags), np.log(tau), 1)[0])\n",
    "            \n",
    "        df['hurst'] = df['spread'].rolling(60, min_periods=20).apply(hurst, raw=False)\n",
    "        plt.subplot(3,2,4)\n",
    "        plt.plot(df['date'], df['hurst'])\n",
    "        plt.axhline(0.5, color='red', linestyle='--', label='Random Walk')\n",
    "        plt.title('60D Rolling Hurst Exponent')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot 5: OU Process Params\n",
    "        def ou_theta(series):\n",
    "            series = series.dropna().values\n",
    "            if len(series) < 10:\n",
    "                return np.nan\n",
    "            X = sm.add_constant(series[:-1])\n",
    "            y = np.diff(series)\n",
    "            try:\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                return float(-np.log(model.params[1])) if model.params[1] > 0 else np.nan\n",
    "            except:\n",
    "                return np.nan\n",
    "        \n",
    "        def ou_theta(series):\n",
    "            \"\"\"Calculate OU mean-reversion speed with robust error handling\"\"\"\n",
    "            series = series.dropna().values\n",
    "            if len(series) < 10:  # Minimum data points for regression\n",
    "                return np.nan\n",
    "    \n",
    "            X = series[:-1]  # Lagged values\n",
    "            y = np.diff(series)  # Differences\n",
    "            X = sm.add_constant(X)  # Add intercept term\n",
    "    \n",
    "            try:\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                # Ensure coefficient is valid for mean-reversion (0 < beta < 1)\n",
    "                beta = model.params[1]\n",
    "                if 0 < beta < 1:\n",
    "                    return float(-np.log(beta))\n",
    "                return np.nan\n",
    "            except:\n",
    "                return np.nan\n",
    "\n",
    "        # Calculate with debugging\n",
    "        df['ou_theta'] = np.nan\n",
    "        for i in range(60, len(df)):\n",
    "            window = df['spread'].iloc[i-60:i]\n",
    "            theta = ou_theta(window)\n",
    "            if not np.isnan(theta):\n",
    "                df.at[df.index[i], 'ou_theta'] = theta\n",
    "\n",
    "        # Diagnostic print\n",
    "        print(\"OU Theta Summary:\")\n",
    "        print(f\"Calculated values: {df['ou_theta'].count()}/{len(df)}\")\n",
    "        print(f\"Mean theta: {df['ou_theta'].mean():.2f}\")\n",
    "        print(f\"Max theta: {df['ou_theta'].max():.2f}\")\n",
    "            \n",
    "        def ou_mu(series):\n",
    "            series = series.dropna().values\n",
    "            if len(series) < 10:\n",
    "                return np.nan\n",
    "            X = sm.add_constant(series[:-1])\n",
    "            y = np.diff(series)\n",
    "            try:\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                return float(model.params[0]/(1-model.params[1])) if model.params[1] != 1 else np.nan\n",
    "            except:\n",
    "                return np.nan\n",
    "                \n",
    "        df['ou_theta'] = df['spread'].rolling(60, min_periods=10).apply(ou_theta, raw=False)\n",
    "        df['ou_mu'] = df['spread'].rolling(60, min_periods=10).apply(ou_mu, raw=False)\n",
    "        \n",
    "        plt.subplot(3,2,5)\n",
    "        plt.plot(df['date'], df['ou_theta'])\n",
    "        plt.title('60D Rolling OU Mean-Reversion Speed (θ)')\n",
    "        \n",
    "        plt.subplot(3,2,6)\n",
    "        plt.plot(df['date'], df['ou_mu'])\n",
    "        plt.title('60D Rolling OU Long-Term Mean (μ)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "# ======================\n",
    "# MAIN EXECUTION\n",
    "def main():\n",
    "    try:\n",
    "        print(\"Starting analysis...\")\n",
    "        \n",
    "        # Process data\n",
    "        df = process_data()\n",
    "        \n",
    "        # Save results\n",
    "        df.to_csv(CSV_PATH, index=False, float_format='%.6f')\n",
    "        print(f\"\\nAnalysis saved to: {CSV_PATH}\")\n",
    "        \n",
    "        # Show sample & stats\n",
    "        print(\"\\nFirst & last 10 rows of processed data:\")\n",
    "        print(df.head(10))\n",
    "        print(df.tail(10))\n",
    "        \n",
    "        # Print key stats\n",
    "        print(\"\\nKey Statistics:\")\n",
    "        print(f\"Average Annualized Basis: {df['basis_annual_pct'].mean():.2f}%\")\n",
    "        print(f\"Average Annualized Funding: {df['funding_annual_pct'].mean():.2f}%\")\n",
    "        print(f\"Max Basis: {df['basis_absolute'].max():.2f} USD\")\n",
    "        print(f\"Min Basis: {df['basis_absolute'].min():.2f} USD\")\n",
    "        print(f\"Basis Annualized Volatility: {df['basis_annual_pct'].std() * np.sqrt(365):.2f}%\")\n",
    "        print(f\"Funding Annualized Volatility: {df['funding_annual_pct'].std() * np.sqrt(365):.2f}%\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        create_visualizations(df)\n",
    "        print(f\"\\nVisualizations saved to: {PDF_PATH}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during analysis: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------BTC Spread Trading Analysis 1 ------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import datetime\n",
    "from textwrap import wrap\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Set up dir\n",
    "INPUT_DIR = \"./processed_data/\"\n",
    "OUTPUT_DIR = \"./reports/\"\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Set up plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Strategy parameters\n",
    "ENTRY_THRESHOLD = 5.0         # % spread threshold to enter trades\n",
    "EXIT_THRESHOLD = 1.0          # % spread threshold to exit trades\n",
    "CAPITAL_PER_TRADE = 10000     # Base capital allocation per trade\n",
    "TRADING_FEE = 0.0005          # 0.05% trading fee per trade\n",
    "\n",
    "def load_clean_data():\n",
    "    \"\"\"Load & process data from processed_data dir\"\"\"\n",
    "    try:\n",
    "        input_path = os.path.join(INPUT_DIR, \"btc_basis_analysis.csv\")\n",
    "        \n",
    "        # Read CSV with fresh new DF\n",
    "        df = pd.read_csv(input_path, parse_dates=['date'])\n",
    "        \n",
    "        # Validate required columns\n",
    "        required_cols = ['date', 'spot_price', 'futures_price', 'basis_annual_pct', 'funding_annual_pct']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            missing = set(required_cols) - set(df.columns)\n",
    "            raise ValueError(f\"CSV missing required columns: {missing}\")\n",
    "            \n",
    "        # Clean data types\n",
    "        numeric_cols = ['spot_price', 'futures_price', 'basis_annual_pct', 'funding_annual_pct']\n",
    "        for col in numeric_cols:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        # Calc add'l metrics\n",
    "        df['basis_absolute'] = df['futures_price'] - df['spot_price']\n",
    "        df['basis_daily_pct'] = (df['basis_absolute'] / df['spot_price']) * 100\n",
    "        df['spread'] = df['basis_annual_pct'] - df['funding_annual_pct']\n",
    "        \n",
    "        # Sort by date & reset index\n",
    "        df = df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        # Validate time continuity\n",
    "        date_diff = df['date'].diff().dt.days.dropna()\n",
    "        if any(date_diff > 1):\n",
    "            gaps = date_diff[date_diff > 1]\n",
    "            print(f\"Warning: Gaps detected in date series: {gaps}\")\n",
    "        \n",
    "        print(f\"\\nData loaded successfully from {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "        print(\"Available columns:\", df.columns.tolist())\n",
    "        print(\"\\nSample data:\")\n",
    "        print(df.head(3))\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"btc_basis_analysis.csv not found in {INPUT_DIR}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading CSV: {str(e)}\")\n",
    "\n",
    "def backtest_strategy(df, entry_thresh=ENTRY_THRESHOLD, exit_thresh=EXIT_THRESHOLD):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Initialize columns\n",
    "    df['position'] = 0  # 1=long spread, -1=short spread, 0=flat\n",
    "    df['trade_id'] = 0\n",
    "    df['pnl'] = 0.0\n",
    "    df['daily_returns'] = 0.0\n",
    "    df['cumulative_pnl'] = 0.0\n",
    "    df['trade_pnl'] = 0.0\n",
    "    \n",
    "    current_position = 0\n",
    "    current_trade_id = 0\n",
    "    entry_spot = None\n",
    "    entry_futures = None\n",
    "    entry_spread = None\n",
    "    cumulative_pnl = 0\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        prev_row = df.iloc[i-1]\n",
    "        curr_row = df.iloc[i]\n",
    "        \n",
    "        # Calc px changes\n",
    "        spot_return = (curr_row['spot_price'] - prev_row['spot_price']) / prev_row['spot_price']\n",
    "        futures_return = (curr_row['futures_price'] - prev_row['futures_price']) / prev_row['futures_price']\n",
    "        \n",
    "        # Entry conditions\n",
    "        if current_position == 0:\n",
    "            if curr_row['spread'] > entry_thresh:\n",
    "                current_position = 1\n",
    "                current_trade_id += 1\n",
    "                entry_spot = curr_row['spot_price']\n",
    "                entry_futures = curr_row['futures_price']\n",
    "                entry_spread = curr_row['spread']\n",
    "                # Apply trading fees\n",
    "                df.at[i, 'pnl'] = -CAPITAL_PER_TRADE * TRADING_FEE * 2  # Pay fee for both legs\n",
    "            elif curr_row['spread'] < -entry_thresh:\n",
    "                current_position = -1\n",
    "                current_trade_id += 1\n",
    "                entry_spot = curr_row['spot_price']\n",
    "                entry_futures = curr_row['futures_price']\n",
    "                entry_spread = curr_row['spread']\n",
    "                # Apply trading fees\n",
    "                df.at[i, 'pnl'] = -CAPITAL_PER_TRADE * TRADING_FEE * 2\n",
    "        \n",
    "        # Position mgmt\n",
    "        elif current_position != 0:\n",
    "            \n",
    "            # CalcDaily P&L\n",
    "            if current_position == 1:\n",
    "                daily_pnl = CAPITAL_PER_TRADE * (spot_return - futures_return)\n",
    "            else:\n",
    "                daily_pnl = CAPITAL_PER_TRADE * (futures_return - spot_return)\n",
    "            \n",
    "            df.at[i, 'pnl'] = daily_pnl\n",
    "            \n",
    "            # Exit conditions\n",
    "            if (current_position == 1 and abs(curr_row['spread']) < exit_thresh) or \\\n",
    "               (current_position == -1 and abs(curr_row['spread']) < exit_thresh):\n",
    "                # Apply trading fees on exit\n",
    "                df.at[i, 'pnl'] -= CAPITAL_PER_TRADE * TRADING_FEE * 2\n",
    "                current_position = 0\n",
    "                entry_spot = None\n",
    "                entry_futures = None\n",
    "                entry_spread = None\n",
    "                \n",
    "        # Update position tracking\n",
    "        df.at[i, 'position'] = current_position\n",
    "        df.at[i, 'trade_id'] = current_trade_id if current_position != 0 else 0\n",
    "        \n",
    "        # Update cumulative P&L\n",
    "        cumulative_pnl += df.at[i, 'pnl']\n",
    "        df.at[i, 'cumulative_pnl'] = cumulative_pnl\n",
    "        df.at[i, 'daily_returns'] = df.at[i, 'pnl'] / CAPITAL_PER_TRADE\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_trade_history(df):\n",
    "    \"\"\"Generate complete trade history w/accurate P&L\"\"\"\n",
    "    trades = []\n",
    "    current_trade = None\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        # New trade started\n",
    "        if row['trade_id'] != 0 and (current_trade is None or current_trade['id'] != row['trade_id']):\n",
    "            if current_trade is not None and current_trade['exit_date'] is None:\n",
    "                # Close previous trade if it wasn't closed properly\n",
    "                current_trade['exit_date'] = row['date']\n",
    "                current_trade['exit_spot'] = row['spot_price']\n",
    "                current_trade['exit_futures'] = row['futures_price']\n",
    "                current_trade['exit_spread'] = row['spread']\n",
    "                trades.append(current_trade)\n",
    "            \n",
    "            current_trade = {\n",
    "                'id': row['trade_id'],\n",
    "                'direction': 'long' if row['position'] == 1 else 'short',\n",
    "                'entry_date': row['date'],\n",
    "                'entry_spot': row['spot_price'],\n",
    "                'entry_futures': row['futures_price'],\n",
    "                'entry_spread': row['spread'],\n",
    "                'exit_date': None,\n",
    "                'exit_spot': None,\n",
    "                'exit_futures': None,\n",
    "                'exit_spread': None,\n",
    "                'capital': CAPITAL_PER_TRADE,\n",
    "                'fees': CAPITAL_PER_TRADE * TRADING_FEE * 2  # Entry fees\n",
    "            }\n",
    "        \n",
    "        # Trade closed\n",
    "        elif row['trade_id'] == 0 and current_trade is not None:\n",
    "            current_trade['exit_date'] = row['date']\n",
    "            current_trade['exit_spot'] = row['spot_price']\n",
    "            current_trade['exit_futures'] = row['futures_price']\n",
    "            current_trade['exit_spread'] = row['spread']\n",
    "            current_trade['fees'] += CAPITAL_PER_TRADE * TRADING_FEE * 2  # Exit fees\n",
    "            trades.append(current_trade)\n",
    "            current_trade = None\n",
    "    \n",
    "    # Handle any open trade at end of period\n",
    "    if current_trade is not None and current_trade['exit_date'] is None:\n",
    "        last_row = df.iloc[-1]\n",
    "        current_trade['exit_date'] = last_row['date']\n",
    "        current_trade['exit_spot'] = last_row['spot_price']\n",
    "        current_trade['exit_futures'] = last_row['futures_price']\n",
    "        current_trade['exit_spread'] = last_row['spread']\n",
    "        current_trade['fees'] += CAPITAL_PER_TRADE * TRADING_FEE * 2  # Exit fees\n",
    "        trades.append(current_trade)\n",
    "    \n",
    "    # Convert to DF & calc metrics\n",
    "    trade_df = pd.DataFrame(trades)\n",
    "    if not trade_df.empty:\n",
    "        trade_df['duration_days'] = (trade_df['exit_date'] - trade_df['entry_date']).dt.days\n",
    "        \n",
    "        # Calc trade returns\n",
    "        for idx, trade in trade_df.iterrows():\n",
    "            if trade['direction'] == 'long':\n",
    "                spot_return = (trade['exit_spot'] - trade['entry_spot']) / trade['entry_spot']\n",
    "                futures_return = (trade['entry_futures'] - trade['exit_futures']) / trade['entry_futures']\n",
    "            else:\n",
    "                spot_return = (trade['entry_spot'] - trade['exit_spot']) / trade['entry_spot']\n",
    "                futures_return = (trade['exit_futures'] - trade['entry_futures']) / trade['entry_futures']\n",
    "            \n",
    "            gross_return = (spot_return + futures_return) * CAPITAL_PER_TRADE\n",
    "            net_return = gross_return - trade['fees']\n",
    "            trade_df.at[idx, 'gross_return'] = gross_return\n",
    "            trade_df.at[idx, 'net_return'] = net_return\n",
    "            trade_df.at[idx, 'return_pct'] = (net_return / CAPITAL_PER_TRADE) * 100\n",
    "        \n",
    "        # ../processed_data/btc_trade_history.csv - format for display\n",
    "        trade_history = pd.DataFrame({\n",
    "            'date': trade_df['entry_date'],\n",
    "            'type': 'enter ' + trade_df['direction'],\n",
    "            'capital': trade_df['capital'],\n",
    "            'spot_price': trade_df['entry_spot'],\n",
    "            'futures_price': trade_df['entry_futures'],\n",
    "            'spread': trade_df['entry_spread'],\n",
    "            'duration_days': None,\n",
    "            'return_pct': None})\n",
    "        \n",
    "        exit_rows = pd.DataFrame({\n",
    "            'date': trade_df['exit_date'],\n",
    "            'type': 'exit ' + trade_df['direction'],\n",
    "            'capital': trade_df['capital'] + trade_df['net_return'],\n",
    "            'spot_price': trade_df['exit_spot'],\n",
    "            'futures_price': trade_df['exit_futures'],\n",
    "            'spread': trade_df['exit_spread'],\n",
    "            'duration_days': trade_df['duration_days'],\n",
    "            'return_pct': trade_df['return_pct']})\n",
    "        \n",
    "        trade_history = pd.concat([trade_history, exit_rows]).sort_values('date')\n",
    "    else:\n",
    "        trade_history = pd.DataFrame()\n",
    "    \n",
    "    return trade_history, trade_df\n",
    "\n",
    "def calculate_performance_metrics(df, trade_df):\n",
    "    if df.empty:\n",
    "        return {\n",
    "            'Total Return (%)': 0,\n",
    "            'Annualized Return (%)': 0,\n",
    "            'Annualized Sharpe': 0,\n",
    "            'Max Drawdown (%)': 0,\n",
    "            'Total Trades': 0,\n",
    "            'Win Rate (%)': 0,\n",
    "            'Avg Win (%)': 0,\n",
    "            'Avg Loss (%)': 0,\n",
    "            'Profit Factor': 0,\n",
    "            'Avg Trade Duration': 0,\n",
    "            'Expectancy (%)': 0\n",
    "        }\n",
    "    \n",
    "    # Calc returns\n",
    "    daily_returns = df['daily_returns'].dropna()\n",
    "    cumulative_returns = (1 + daily_returns).cumprod()\n",
    "    total_return = (cumulative_returns.iloc[-1] - 1) * 100\n",
    "    \n",
    "    # Annualized return\n",
    "    days_in_sample = (df['date'].iloc[-1] - df['date'].iloc[0]).days\n",
    "    annualized_return = ((1 + total_return/100)**(365/days_in_sample) - 1) * 100\n",
    "    \n",
    "    # Sharpe ratio (annualized)\n",
    "    if len(daily_returns) > 1:\n",
    "        sharpe_ratio = (daily_returns.mean() / daily_returns.std()) * np.sqrt(365)\n",
    "    else:\n",
    "        sharpe_ratio = 0\n",
    "    \n",
    "    # Max drawdown\n",
    "    cumulative_returns_pct = (cumulative_returns - 1) * 100\n",
    "    rolling_max = cumulative_returns_pct.cummax()\n",
    "    drawdown = cumulative_returns_pct - rolling_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Trade metrics\n",
    "    if not trade_df.empty:\n",
    "        total_trades = len(trade_df)\n",
    "        winning_trades = len(trade_df[trade_df['net_return'] > 0])\n",
    "        win_rate = (winning_trades / total_trades) * 100 if total_trades > 0 else 0\n",
    "        \n",
    "        avg_win = trade_df[trade_df['net_return'] > 0]['return_pct'].mean() if winning_trades > 0 else 0\n",
    "        avg_loss = trade_df[trade_df['net_return'] < 0]['return_pct'].mean() if (total_trades - winning_trades) > 0 else 0\n",
    "        \n",
    "        gross_profit = trade_df[trade_df['net_return'] > 0]['net_return'].sum()\n",
    "        gross_loss = abs(trade_df[trade_df['net_return'] < 0]['net_return'].sum())\n",
    "        profit_factor = gross_profit / gross_loss if gross_loss > 0 else float('inf')\n",
    "        \n",
    "        avg_duration = trade_df['duration_days'].mean()\n",
    "        expectancy = (win_rate/100 * avg_win) + ((100-win_rate)/100 * avg_loss)\n",
    "    else:\n",
    "        total_trades = 0\n",
    "        win_rate = 0\n",
    "        avg_win = 0\n",
    "        avg_loss = 0\n",
    "        profit_factor = 0\n",
    "        avg_duration = 0\n",
    "        expectancy = 0\n",
    "    \n",
    "    return {\n",
    "        'Total Return (%)': total_return,\n",
    "        'Annualized Return (%)': annualized_return,\n",
    "        'Annualized Sharpe': sharpe_ratio,\n",
    "        'Max Drawdown (%)': max_drawdown,\n",
    "        'Total Trades': total_trades,\n",
    "        'Win Rate (%)': win_rate,\n",
    "        'Avg Win (%)': avg_win,\n",
    "        'Avg Loss (%)': avg_loss,\n",
    "        'Profit Factor': profit_factor,\n",
    "        'Avg Trade Duration': avg_duration,\n",
    "        'Expectancy (%)': expectancy\n",
    "    }\n",
    "\n",
    "def run_sensitivity_analysis(df):\n",
    "    \"\"\"Run threshold sensitivity analysis\"\"\"\n",
    "    thresholds = np.arange(1, 11, 0.5)  # Test thresholds from 1% to 10%\n",
    "    results = []\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        temp_df = backtest_strategy(df, entry_thresh=thresh, exit_thresh=1.0)\n",
    "        trade_history, trade_df = generate_trade_history(temp_df)\n",
    "        metrics = calculate_performance_metrics(temp_df, trade_df)\n",
    "        results.append({\n",
    "            'Threshold': thresh,\n",
    "            'Total Return': metrics['Total Return (%)'],\n",
    "            'Sharpe Ratio': metrics['Annualized Sharpe'],\n",
    "            'Win Rate': metrics['Win Rate (%)'],\n",
    "            'Profit Factor': metrics['Profit Factor'],\n",
    "            'Max Drawdown': metrics['Max Drawdown (%)']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def generate_trading_report(df, trade_history, trade_df, metrics, sensitivity_df):\n",
    "    \"\"\"Generate comprehensive PDF report\"\"\"\n",
    "    report_path = os.path.join(OUTPUT_DIR, 'BTC_Spread_Trading_Report_1.pdf')\n",
    "    \n",
    "    with PdfPages(report_path) as pdf:\n",
    "    \n",
    "        # Strategy overview\n",
    "        plt.figure(figsize=(11, 8))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        strategy_text = [\n",
    "            \"Strategy Overview:\",\n",
    "            \"\",\n",
    "            \"This strategy trades the spread between Bitcoin's annualized basis (futures premium)\",\n",
    "            \"& funding rate (Spread = Basis - Funding). The strategy aims to capture mean-reversion\",\n",
    "            \"opportunities when the spread deviates significantly from its historical average.\",\n",
    "            \"\",\n",
    "            \"Position Rules:\",\n",
    "            \"  LONG SPREAD: Buy spot + Sell futures when spread > +5%\",\n",
    "            \"  SHORT SPREAD: Sell spot + Buy futures when spread < -5%\",\n",
    "            \"  EXIT: Close position when spread returns within ±1%\",\n",
    "            \"\",\n",
    "            f\"Parameters: Entry Threshold ±{ENTRY_THRESHOLD}% | Exit Threshold ±{EXIT_THRESHOLD}%\",\n",
    "            f\"Capital per Trade: ${CAPITAL_PER_TRADE:,.0f} | Trading Fees: {TRADING_FEE*100:.2f}% per leg\"\n",
    "        ]\n",
    "        \n",
    "        plt.text(0.05, 0.9, '\\n'.join(strategy_text), \n",
    "                ha='left', va='top', fontsize=11, linespacing=1.5)\n",
    "        \n",
    "        # Performance summary table\n",
    "        plt.text(0.05, 0.4, 'Performance Summary:', \n",
    "                ha='left', va='top', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        perf_data = [\n",
    "            ['Total Return', f\"{metrics['Total Return (%)']:.2f}%\"],\n",
    "            ['Annualized Return', f\"{metrics['Annualized Return (%)']:.2f}%\"],\n",
    "            ['Sharpe Ratio', f\"{metrics['Annualized Sharpe']:.2f}\"],\n",
    "            ['Max Drawdown', f\"{metrics['Max Drawdown (%)']:.2f}%\"],\n",
    "            ['Total # Roundtrip Trades', metrics['Total Trades']],\n",
    "            ['Win Rate', f\"{metrics['Win Rate (%)']:.1f}%\"],\n",
    "            ['Profit Factor', f\"{metrics['Profit Factor']:.2f}\"],\n",
    "            ['Avg Trade Duration', f\"{metrics['Avg Trade Duration']:.1f} days\"]\n",
    "        ]\n",
    "        \n",
    "        table = plt.table(cellText=perf_data,\n",
    "                        colWidths=[0.3, 0.2],\n",
    "                        cellLoc='left',\n",
    "                        loc='bottom left',\n",
    "                        bbox=[0.05, 0.1, 0.9, 0.25])\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(11)\n",
    "        \n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "        # Spread & signals plot\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(11, 8))\n",
    "        ax[0].plot(df['date'], df['basis_annual_pct'], label='Annualized Basis', color='blue')  \n",
    "        ax[0].plot(df['date'], df['funding_annual_pct'], label='Annualized Funding', color='red')  \n",
    "        ax[0].fill_between(df['date'], df['basis_annual_pct'], df['funding_annual_pct'], \n",
    "                        where=(df['basis_annual_pct']>df['funding_annual_pct']),  \n",
    "                        color='green', alpha=0.3, label='Positive Spread')\n",
    "        ax[0].axhline(ENTRY_THRESHOLD, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax[0].axhline(-ENTRY_THRESHOLD, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax[0].set_title('BTC Basis vs Funding Rate Spread')\n",
    "        ax[0].legend()\n",
    "        ax[0].set_ylabel('Annualized %')\n",
    "\n",
    "        ax[1].plot(df['date'], df['position'], label='Strategy Position', \n",
    "                drawstyle='steps-post', color='purple', linewidth=2)\n",
    "        ax[1].axhline(0, color='black', linestyle='-', alpha=0.5)\n",
    "        ax[1].set_yticks([-1, 0, 1])\n",
    "        ax[1].set_yticklabels(['Short\\nSpread', 'Flat', 'Long\\nSpread'])\n",
    "        ax[1].set_title('Strategy Signals')\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "        # Drawdown\n",
    "        plt.figure(figsize=(11, 4))\n",
    "        equity = (1 + df['daily_returns'].fillna(0)).cumprod()\n",
    "        rolling_max = equity.cummax()\n",
    "        drawdown = (equity - rolling_max) / rolling_max * 100\n",
    "        \n",
    "        drawdown.plot(color='red', label='Drawdown')\n",
    "        plt.fill_between(drawdown.index, drawdown, color='red', alpha=0.3)\n",
    "        plt.title('Strategy Drawdown')\n",
    "        plt.ylabel('Drawdown (%)')\n",
    "        plt.legend()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "        # Trade analysis\n",
    "        if not trade_df.empty:\n",
    "            # Returns distribution\n",
    "            plt.figure(figsize=(11, 6))\n",
    "            plt.subplot(121)\n",
    "            sns.histplot(trade_df['return_pct'], bins=20, kde=True)\n",
    "            plt.title('Trade Returns Distribution')\n",
    "            plt.xlabel('Return (%)')\n",
    "            \n",
    "            # Duration vs Returns\n",
    "            plt.subplot(122)\n",
    "            sns.scatterplot(data=trade_df, x='duration_days', y='return_pct', hue='direction')\n",
    "            plt.title('Trade Duration vs Returns')\n",
    "            plt.xlabel('Duration (days)')\n",
    "            plt.ylabel('Return (%)')\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "            \n",
    "            # Cum. returns by trade\n",
    "            plt.figure(figsize=(11, 6))\n",
    "            trade_df = trade_df.sort_values('exit_date')\n",
    "            trade_df['cumulative_return'] = (1 + trade_df['return_pct']/100).cumprod() * CAPITAL_PER_TRADE\n",
    "            plt.plot(trade_df['exit_date'], trade_df['cumulative_return'])\n",
    "            plt.title('Cumulative Returns by Trade')\n",
    "            plt.ylabel('Portfolio Value ($)')\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "        \n",
    "        # Sensitivity analysis\n",
    "        plt.figure(figsize=(11, 8))\n",
    "        plt.subplot(221)\n",
    "        plt.plot(sensitivity_df['Threshold'], sensitivity_df['Total Return'], 'o-')\n",
    "        plt.title('Total Return by Entry Threshold')\n",
    "        plt.xlabel('Threshold (%)')\n",
    "        plt.ylabel('Return (%)')\n",
    "        \n",
    "        plt.subplot(222)\n",
    "        plt.plot(sensitivity_df['Threshold'], sensitivity_df['Sharpe Ratio'], 'o-')\n",
    "        plt.title('Sharpe Ratio by Entry Threshold')\n",
    "        plt.xlabel('Threshold (%)')\n",
    "        plt.ylabel('Sharpe Ratio')\n",
    "        \n",
    "        plt.subplot(223)\n",
    "        plt.plot(sensitivity_df['Threshold'], sensitivity_df['Win Rate'], 'o-')\n",
    "        plt.title('Win Rate by Entry Threshold')\n",
    "        plt.xlabel('Threshold (%)')\n",
    "        plt.ylabel('Win Rate (%)')\n",
    "        \n",
    "        plt.subplot(224)\n",
    "        plt.plot(sensitivity_df['Threshold'], sensitivity_df['Max Drawdown'], 'o-')\n",
    "        plt.title('Max Drawdown by Entry Threshold')\n",
    "        plt.xlabel('Threshold (%)')\n",
    "        plt.ylabel('Drawdown (%)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "        # Trade history\n",
    "        if not trade_history.empty:\n",
    "            plt.figure(figsize=(11, 8))\n",
    "            ax = plt.subplot(111)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            display_cols = ['date', 'type', 'capital', 'spot_price', 'futures_price', 'spread', 'duration_days', 'return_pct']\n",
    "            trades_display = trade_history[display_cols].copy()\n",
    "            \n",
    "            trades_display['date'] = trades_display['date'].dt.strftime('%Y-%m-%d')\n",
    "            trades_display['capital'] = trades_display['capital'].apply(lambda x: f\"${x:,.2f}\")\n",
    "            trades_display['spot_price'] = trades_display['spot_price'].apply(lambda x: f\"${x:,.2f}\")\n",
    "            trades_display['futures_price'] = trades_display['futures_price'].apply(lambda x: f\"${x:,.2f}\")\n",
    "            trades_display['spread'] = trades_display['spread'].apply(lambda x: f\"{x:.2f}%\")\n",
    "            trades_display['return_pct'] = trades_display['return_pct'].apply(lambda x: f\"{x:.2f}%\" if pd.notnull(x) else \"N/A\")\n",
    "            \n",
    "            table = ax.table(cellText=trades_display.values,\n",
    "                            colLabels=trades_display.columns,\n",
    "                            cellLoc='center',\n",
    "                            loc='center')\n",
    "            \n",
    "            table.auto_set_font_size(False)\n",
    "            table.set_fontsize(9)\n",
    "            table.scale(1, 1.2)\n",
    "            \n",
    "            for (row, col), cell in table.get_celld().items():\n",
    "                if row == 0:\n",
    "                    cell.set_text_props(weight='bold', color='white')\n",
    "                    cell.set_facecolor('#4b61d1')\n",
    "                else:\n",
    "                    if 'enter' in trades_display.iloc[row-1]['type']:\n",
    "                        cell.set_facecolor('#f0f7f0')\n",
    "                    elif 'exit' in trades_display.iloc[row-1]['type']:\n",
    "                        try:\n",
    "                            return_pct = float(trades_display.iloc[row-1]['return_pct'].replace('%', ''))\n",
    "                            cell.set_facecolor('#e6f3e6' if return_pct > 0 else '#f3e6e6')\n",
    "                        except:\n",
    "                            cell.set_facecolor('#f5f5f5')\n",
    "            \n",
    "            plt.title('Trade History', pad=20, fontsize=14, fontweight='bold')\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"Starting BTC Spread Trading Analysis...\")\n",
    "        \n",
    "        print(\"Loading and cleaning price data...\")      \n",
    "        df = load_clean_data()\n",
    "        \n",
    "        print(\"Running backtest...\")\n",
    "        results = backtest_strategy(df)\n",
    "    \n",
    "        print(\"Analyzing trade history...\")\n",
    "        trade_history, trade_df = generate_trade_history(results)\n",
    "        \n",
    "        print(\"Calc performance metrics...\")\n",
    "        metrics = calculate_performance_metrics(results, trade_df)\n",
    "        \n",
    "        print(\"Running sensitivity analysis...\")\n",
    "        sensitivity_df = run_sensitivity_analysis(df)\n",
    "        \n",
    "        print(\"Generating PDF...\")\n",
    "        generate_trading_report(results, trade_history, trade_df, metrics, sensitivity_df)\n",
    "        \n",
    "    \n",
    "        trade_history.to_csv(\n",
    "            os.path.join(INPUT_DIR, 'btc_trade_history.csv'),\n",
    "            index=False,\n",
    "            float_format='%.6f',\n",
    "            quoting=csv.QUOTE_NONNUMERIC,\n",
    "            quotechar='\"',\n",
    "            encoding='utf-8')\n",
    "        \n",
    "        results.to_csv(\n",
    "            os.path.join(INPUT_DIR, 'btc_backtest_results.csv'),\n",
    "            index=False,\n",
    "            float_format='%.6f',\n",
    "            quoting=csv.QUOTE_MINIMAL,\n",
    "            quotechar='\"',\n",
    "            encoding='utf-8',\n",
    "            date_format='%Y-%m-%d')\n",
    "        \n",
    "        print(f\"\\nAnalysis completed successfully!\")\n",
    "        # [Rest of your print statements]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in analysis: {str(e)}\")\n",
    "  \n",
    "        print(f\"\\nAnalysis completed successfully!\")\n",
    "        print(f\"Report generated: {os.path.join(OUTPUT_DIR, 'BTC_Spread_Trading_Report_1.pdf')}\")\n",
    "        print(\"\\nKey Performance Metrics:\")\n",
    "        print(f\"Total Return: {metrics['Total Return (%)']:.2f}%\")\n",
    "        print(f\"Annualized Return: {metrics['Annualized Return (%)']:.2f}%\")\n",
    "        print(f\"Sharpe Ratio: {metrics['Annualized Sharpe']:.2f}\")\n",
    "        print(f\"Win Rate: {metrics['Win Rate (%)']:.1f}%\")\n",
    "        print(f\"Profit Factor: {metrics['Profit Factor']:.2f}\")\n",
    "        print(f\"Max Drawdown: {metrics['Max Drawdown (%)']:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in analysis: {str(e)}\")    \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from importlib.util import find_spec\n",
    "\n",
    "def ensure_pypdf2():\n",
    "    \"\"\"Ensure PyPDF2 is available with fallbacks\"\"\"\n",
    "    if find_spec(\"PyPDF2\"):\n",
    "        try:\n",
    "            from PyPDF2 import PdfMerger\n",
    "            return PdfMerger\n",
    "        except ImportError:\n",
    "            try:\n",
    "                from PyPDF2 import PdfFileMerger as PdfMerger\n",
    "                return PdfMerger\n",
    "            except ImportError:\n",
    "                pass\n",
    "    \n",
    "    # If we get here, installation is needed\n",
    "    print(\"Installing PyPDF2...\")\n",
    "    try:\n",
    "        import pip\n",
    "        pip.main(['install', 'PyPDF2'])\n",
    "    except:\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'PyPDF2'])\n",
    "    \n",
    "    # Try imports again after installation\n",
    "    from PyPDF2 import PdfMerger\n",
    "    return PdfMerger\n",
    "\n",
    "def combine_pdfs(pdf1_path, pdf2_path, output_path):\n",
    "    \"\"\"Robust PDF combining with installation fallback\"\"\"\n",
    "    PdfMerger = ensure_pypdf2()\n",
    "    input_files = [pdf1_path, pdf2_path]  # Store input files for potential deletion\n",
    "    \n",
    "    try:\n",
    "        # Convert to absolute paths\n",
    "        pdf1_path = os.path.abspath(pdf1_path)\n",
    "        pdf2_path = os.path.abspath(pdf2_path)\n",
    "        \n",
    "        print(f\"Looking for files at:\\n- {pdf1_path}\\n- {pdf2_path}\")\n",
    "        \n",
    "        merger = PdfMerger()\n",
    "        for pdf in input_files:\n",
    "            if not os.path.exists(pdf):\n",
    "                raise FileNotFoundError(f\"PDF file not found: {pdf}\")\n",
    "            merger.append(pdf)\n",
    "        \n",
    "        # Create output directory if needed\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        merger.write(output_path)\n",
    "        merger.close()\n",
    "        print(f\"Successfully created: {os.path.abspath(output_path)}\")\n",
    "        \n",
    "        # Delete input files after successful combination\n",
    "        for pdf in input_files:\n",
    "            try:\n",
    "                os.remove(pdf)\n",
    "                print(f\"Deleted input file: {pdf}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not delete {pdf} - {str(e)}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error combining PDFs: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Example usage with verification\n",
    "if __name__ == \"__main__\":\n",
    "    # Get current working directory\n",
    "    cwd = os.getcwd()\n",
    "    print(f\"Current working directory: {cwd}\")\n",
    "    \n",
    "    # Define the reports subdirectory\n",
    "    reports_dir = os.path.join(cwd, \"reports\")\n",
    "    \n",
    "    # List files in reports directory to help debugging\n",
    "    print(\"\\nFiles in reports directory:\")\n",
    "    try:\n",
    "        for f in os.listdir(reports_dir):\n",
    "            if f.lower().endswith('.pdf'):\n",
    "                print(f\"- {f}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Reports directory not found at: {reports_dir}\")\n",
    "    \n",
    "    # Try combining with correct paths\n",
    "    input_pdf1 = os.path.join(reports_dir, \"BTC_Spread_Trading_Report_0.pdf\")\n",
    "    input_pdf2 = os.path.join(reports_dir, \"BTC_Spread_Trading_Report_1.pdf\")\n",
    "    output_pdf = os.path.join(reports_dir, \"BTC_Spread_Trading_Report_Final.pdf\")\n",
    "    \n",
    "    print(f\"\\nAttempting to combine:\\n- {input_pdf1}\\n- {input_pdf2}\")\n",
    "    \n",
    "    if combine_pdfs(input_pdf1, input_pdf2, output_pdf):\n",
    "        print(\"Combination successful!\")\n",
    "        print(f\"Output file created at: {output_pdf}\")\n",
    "    else:\n",
    "        print(\"Failed to combine PDFs\")\n",
    "        print(\"\\nPossible solutions:\")\n",
    "        print(\"1. Verify the PDF files exist in the reports subdirectory\")\n",
    "        print(\"2. Check the filenames are correct (case-sensitive)\")\n",
    "        print(\"3. Ensure you have read/write permissions for the reports directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429098d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
